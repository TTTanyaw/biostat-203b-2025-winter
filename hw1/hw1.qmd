---
title: "Biostat 203B Homework 1"
subtitle: Due Jan 24, 2025 @ 11:59PM
author: Tanya Wang, 605587605
format:
  html:
    typst: default
    theme: cosmo
    embed-resources: true
    number-sections: false
    toc: true
    toc-depth: 4
    toc-location: left
    code-fold: false
    link-external-icon: true
    link-external-newwindow: true
---

Display machine information for reproducibility:
```{r}
#| eval: true
sessionInfo()
```

## Q1. Git/GitHub

**No handwritten homework reports are accepted for this course.** We work with Git and GitHub. Efficient and abundant use of Git, e.g., frequent and well-documented commits, is an important criterion for grading your homework.

1. Apply for the [Student Developer Pack](https://education.github.com/pack) at GitHub using your UCLA email. You'll get GitHub Pro account for free (unlimited public and private repositories).

2. Create a **private** repository `biostat-203b-2025-winter` and add `Hua-Zhou` and TA team (`Tomoki-Okuno` for Lec 1; `parsajamshidian` and `BowenZhang2001` for Lec 82) as your collaborators with write permission.

3. Top directories of the repository should be `hw1`, `hw2`, ... Maintain two branches `main` and `develop`. The `develop` branch will be your main playground, the place where you develop solution (code) to homework problems and write up report. The `main` branch will be your presentation area. Submit your homework files (Quarto file `qmd`, `html` file converted by Quarto, all code and extra data sets to reproduce results) in the `main` branch.

4. After each homework due date, course reader and instructor will check out your `main` branch for grading. Tag each of your homework submissions with tag names `hw1`, `hw2`, ... Tagging time will be used as your submission time. That means if you tag your `hw1` submission after deadline, penalty points will be deducted for late submission.

5. After this course, you can make this repository public and use it to demonstrate your skill sets on job market.

**Question 1 Done**


## Q2. Data ethics training

This exercise (and later in this course) uses the [MIMIC-IV data v3.1](https://physionet.org/content/mimiciv/3.1/), a freely accessible critical care database developed by the MIT Lab for Computational Physiology. Follow the instructions at <https://mimic.mit.edu/docs/gettingstarted/> to (1) complete the CITI `Data or Specimens Only Research` course and (2) obtain the PhysioNet credential for using the MIMIC-IV data. Display the verification links to your completion report and completion certificate here. **You must complete Q2 before working on the remaining questions.** (Hint: The CITI training takes a few hours and the PhysioNet credentialing takes a couple days; do not leave it to the last minute.)

**Solution:** 

Completion Certificate: https://www.citiprogram.org/verify/?wf72ab98b-d60a-444e-9a3b-063bd8d7f7e9-67209420

Completion Report: https://www.citiprogram.org/verify/?wf72ab98b-d60a-444e-9a3b-063bd8d7f7e9-67209420


## Q3. Linux Shell Commands

1. Make the MIMIC-IV v3.1 data available at location `~/mimic`. The output of the `ls -l ~/mimic` command should be similar to the below (from my laptop).
```{bash}
#| eval: true
# content of mimic folder
ls -l ~/mimic/
```
Refer to the documentation <https://physionet.org/content/mimiciv/3.1/> for details of data files. Do **not** put these data files into Git; they are big. Do **not** copy them into your directory. Do **not** decompress the gz data files. These create unnecessary big files and are not big-data-friendly practices. Read from the data folder `~/mimic` directly in following exercises. 

  Use Bash commands to answer following questions.
  
**Solution:** I downloaded the MIMIC IV v3.1 data and it is available under "~/mimic" folder as requested.


2. Display the contents in the folders `hosp` and `icu` using Bash command `ls -l`. Why are these data files distributed as `.csv.gz` files instead of `.csv` (comma separated values) files? Read the page <https://mimic.mit.edu/docs/iv/> to understand what's in each folder.

**Solution:** Here is the content of `hosp` folder
```{bash}
ls -l ~/mimic/hosp/
```

and the content of `icu` folder
```{bash}
ls -l ~/mimic/icu/
```

These data were distributed as `gz` file because they are compressed using gzip, which will reduce the file size and make the download and storage process more efficient. Besides, gzip format includes a checksum feature that ensures the integrity of the data. It also allows people to decompress only the necessary files, saving storage space.


3. Briefly describe what Bash commands `zcat`, `zless`, `zmore`, and `zgrep` do.

**Solution:** 

`zcat`: This command is to display the contents of compressed files directly to the standard output.

`zless`: This command is used for viewing text files one screen at a time in a terminal. zless allows people to view gzip-compressed text files in a paginated form.

`zmore`: This command is for compressed files. It allows people to view the contents of gzip-compressed files page by page.

`zgrep`: This command is to search for patterns within gzip-compressed files without decompressing them, outputting any lines which match the specified patterns.


4. (Looping in Bash) What's the output of the following bash script?
```{bash}
#| eval: true
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  ls -l $datafile
done
```

Display the number of lines in each data file using a similar loop. (Hint: combine linux commands `zcat <` and `wc -l`.)

**Solution:** The bash script looks for any files starting with 'a', 'l', or 'pa' and ending with .gz.

The number of lines in each data file is:
```{bash}
for datafile in ~/mimic/hosp/{a,l,pa}*.gz
do
  zcat < $datafile | wc -l
done
```


5. Display the first few lines of `admissions.csv.gz`. How many rows are in this data file, excluding the header line? Each `hadm_id` identifies a hospitalization. How many hospitalizations are in this data file? How many unique patients (identified by `subject_id`) are in this data file? Do they match the number of patients listed in the `patients.csv.gz` file? (Hint: combine Linux commands `zcat <`, `head`/`tail`, `awk`, `sort`, `uniq`, `wc`, and so on.)

**Solution:** 

Here is the first few lines of `admissions.csv.gz`
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | head
```

The number of rows in this data file, excluding the header line, is:
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | tail -n +2 | wc -l
```

The number of hospitolizations in this file is:
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | 
tail -n +2 | 
awk -F, '{print $2}' | 
sort | 
uniq | 
wc -l
```

The same as number of rows in the file.

Peek the first few lines of `patients.csv.gz`
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | head
```

The number of unique patients in this data file is
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz |
tail -n +2 | 
awk -F, '{print $1}' | 
sort | 
uniq |
wc -l
```

which is less than the number of patients listed in the `patients.csv.gz` file.
```{bash}
zcat < ~/mimic/hosp/patients.csv.gz |
awk -F, '{print $1}' | 
sort | 
uniq |
wc -l
```


6. What are the possible values taken by each of the variable `admission_type`, `admission_location`, `insurance`, and `ethnicity`? Also report the count for each unique value of these variables in decreasing order. (Hint: combine Linux commands `zcat`, `head`/`tail`, `awk`, `uniq -c`, `wc`, `sort`, and so on; skip the header line.)

**Solution:**

Here is the first line of `admissions.csv.gz`
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | head -1
```

Counts for `admission_type` (Column 6):
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | 
tail -n +2 | 
awk -F, '{print $6}' | 
sort | 
uniq -c | 
sort -nr
```

Counts for `admission_location` (Column 8):
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | 
tail -n +2 | 
awk -F, '{print $8}' | 
sort | 
uniq -c | 
sort -nr
```

Counts for `insurance` (Column 10):
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | 
tail -n +2 | 
awk -F, '{print $10}' | 
sort | 
uniq -c | 
sort -nr
```

Counts for `ethnicity` (Column 12):
```{bash}
zcat < ~/mimic/hosp/admissions.csv.gz | 
tail -n +2 | 
awk -F, '{print $12}' | 
sort | 
uniq -c | 
sort -nr
```


7. The `icusays.csv.gz` file contains all the ICU stays during the study period. How many ICU stays, identified by `stay_id`, are in this data file? How many unique patients, identified by `subject_id`, are in this data file?

**Sulotion:**

Here is the first line of `icusays.csv.gz`
```{bash}
zcat < ~/mimic/icu/icustays.csv.gz | head -1
```

The number of ICU stays in this file is:
```{bash}
zcat < ~/mimic/icu/icustays.csv.gz | 
tail -n +2 | 
awk -F, '{print $3}' | 
sort | 
uniq | 
wc -l
```

The number of unique patients in this data file is
```{Bash}
zcat < ~/mimic/icu/icustays.csv.gz | 
tail -n +2 | 
awk -F, '{print $1}' | 
sort | 
uniq |
wc -l
```


8. _To compress, or not to compress. That's the question._ Let's focus on the big data file `labevents.csv.gz`. Compare compressed gz file size to the uncompressed file size. Compare the run times of `zcat < ~/mimic/labevents.csv.gz | wc -l` versus `wc -l labevents.csv`. Discuss the trade off between storage and speed for big data files. (Hint: `gzip -dk < FILENAME.gz > ./FILENAME`. Remember to delete the large `labevents.csv` file after the exercise.)

**Solution:**

The compressed file size is:
```{bash}
ls -lh ~/mimic/hosp/labevents.csv.gz
```

The uncompressed file size is:
```{bash}
# gzip -dk < ~/mimic/hosp/labevents.csv.gz > ./labevents.csv
ls -lh ./labevents.csv
```

The runtime comparison:
```{bash}
time zcat < ~/mimic/hosp/labevents.csv.gz | wc -l
```

```{bash}
time wc -l labevents.csv
```

Compressed files significantly reduce storage needs, which can save costs and minimize data transfer bandwidth. However, they require additional CPU resources for decompression, which will slow down data processing. Uncompressed files, while larger, provide faster access and processing speeds. Therefore, if storage is limited and CPU resources are abundant, compression will be preferable. Instead, if speed and quick data access are required, and sufficient storage is available, uncompressed data file will be better.


## Q4. Who's popular in Price and Prejudice

1. You and your friend just have finished reading *Pride and Prejudice* by Jane Austen. Among the four main characters in the book, Elizabeth, Jane, Lydia, and Darcy, your friend thinks that Darcy was the most mentioned. You, however, are certain it was Elizabeth. Obtain the full text of the novel from <http://www.gutenberg.org/cache/epub/42671/pg42671.txt> and save to your local folder. 
```{bash}
#| eval: true
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
```

Explain what `wget -nc` does. Do **not** put this text file `pg42671.txt` in Git. Complete the following loop to tabulate the number of times each of the four characters is mentioned using Linux commands.
```{bash}
#| eval: true
wget -nc http://www.gutenberg.org/cache/epub/42671/pg42671.txt
for char in Elizabeth Jane Lydia Darcy
do
  echo $char:
  grep -o $char pg42671.txt | wc -l
done
```

**Solution:**

The `wget -nc` command is used to download files from the internet. The -nc option tells wget not to download a file if it already exists in the specified location. 


2. What's the difference between the following two commands?
```{bash}
#| eval: true
echo 'hello, world' > test1.txt
```
and
```{bash}
#| eval: true
echo 'hello, world' >> test2.txt
```

**Solution:**

`echo 'hello, world' > test1.txt` writes the string 'hello, world' to the file test1.txt, replacing any existing content within the file. If test1.txt does not exist, it will create the file.

`echo 'hello, world' >> test2.txt` appends the string 'hello, world' to the end of test2.txt. If test2.txt does not exist, it will also create the file. 

The difference between them is that `>>` will append to rather than replacing the file's content.


3. Using your favorite text editor (e.g., `vi`), type the following and save the file as `middle.sh`:
```{bash eval=FALSE}
#!/bin/sh
# Select lines from the middle of a file.
# Usage: bash middle.sh filename end_line num_lines
head -n "$2" "$1" | tail -n "$3"
```
Using `chmod` to make the file executable by the owner, and run
```{bash}
#| eval: true
./middle.sh pg42671.txt 20 5
```
Explain the output. Explain the meaning of `"$1"`, `"$2"`, and `"$3"` in this shell script. Why do we need the first line of the shell script?

**Solution:** 

The output shows the information of an eBook. Its release date is May 9, 2013, and its identifier is eBook #42671. It also shows that the eBook is written in English.

"$1", "$2", and "$3" are positional parameters used in shell scripts:

"$1" is the first argument passed to the script, which is filename her.

"$2" represents the second argument, which is end_line here. It determines how many lines from the start of the file will be considered for the future process.

"\$3" is the third argument, which is num_lines, and it indicates the number of lines to be displayed from the end of the range specified by "\$2".

The first line of the shell script, #!/bin/sh, is called a shebang. It tells the operating system which interpreter to use to run the script. Without this line, the script would require the user to manually specify which interpreter to use, which is not convenient.



## Q5. More fun with Linux

Try following commands in Bash and interpret the results: `cal`, `cal 2025`, `cal 9 1752` (anything unusual?), `date`, `hostname`, `arch`, `uname -a`, `uptime`, `who am i`, `who`, `w`, `id`, `last | head`, `echo {con,pre}{sent,fer}{s,ed}`, `time sleep 5`, `history | tail`.

`cal` displays the calendar of the current month:
```{bash}
cal
```

`cal 2025` displays the calendar of year 2025:
```{bash}
cal 2025
```

`cal 9 1752` displays the calendar of September 1752:
```{bash}
cal 9 1752
```

One special thing is that this month misses several days (9.3-9.13). According to the materials, this is because of the adoption of the Gregorian calendar by Britain and its colonies, which required an adjustment of 11 days to correct for accumulated discrepancies over centuries.

`date` displays the current date and time:
```{bash}
date
```

`hostname` displays the name of computer I am using:
```{bash}
hostname
```

`arch` outputs the architecture of the processor in the machine:
```{bash}
arch
```

`uname -a` displays the kernel name, hostname, kernel release, kernel version, machine, processor, hardware platform, and operating system of the system:
```{bash}
uname -a
```

`uptime` shows how long the system has been running since its last startup, along with the current number of users and load averages for the past 1, 5, and 15 minutes:
```{bash}
uptime
```

`who am i` shows who I am logged in with and login time:
```{bash}
who am i
```

`who` shows the login name, terminal line, and login time of the user currently logged into the computer:
```{bash}
who
```

`w` shows who is currently using the system, their activities, and the system’s current load:
```{bash}
w
```

`id` displays the user and group information for the current user, showing user ID, group ID, and the groups the user is part of:
```{bash}
id
```

`last | head` shows the last several logins in the system, how long each session lasted, and from where the login occurred:
```{bash}
last | head
```

`echo {con, pre}{sent, fer}{s, ed}` uses brace expansion to generate combinations of the specified elements:
```{bash}
echo {con, pre}{sent, fer}{s, ed}
```

`time sleep 5` measures the time taken to execute sleep 5, which pauses the command line for 5 seconds:
```{bash}
time sleep 5
```

`history | tail` displays the last few commands I have executed in the terminal
```{bash}
history | tail
```


## Q6. Book

1. Git clone the repository <https://github.com/christophergandrud/Rep-Res-Book> for the book _Reproducible Research with R and RStudio_ to your local machine. Do **not** put this repository within your homework repository `biostat-203b-2025-winter`.

**Solution:** Done.

2. Open the project by clicking `rep-res-3rd-edition.Rproj` and compile the book by clicking `Build Book` in the `Build` panel of RStudio. (Hint: I was able to build `git_book` and `epub_book` directly. For `pdf_book`, I needed to add a line `\usepackage{hyperref}` to the file `Rep-Res-Book/rep-res-3rd-edition/latex/preabmle.tex`.)

The point of this exercise is (1) to obtain the book for free and (2) to see an example how a complicated project such as a book can be organized in a reproducible way. Use `sudo apt install PKGNAME` to install required Ubuntu packages and `tlmgr install PKGNAME` to install missing TexLive packages.

For grading purpose, include a screenshot of Section 4.1.5 of the book here.

**Solution:**

![Section 4.1.5](4.1.5.png)